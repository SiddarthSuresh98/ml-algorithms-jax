# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fgDx1w8sv3uGfUYXsScveuOJQRG8JITG
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder,LabelEncoder, StandardScaler
from tensorflow.keras import models, layers

df_train = pd.read_csv(r"./train.csv")

df_train = df_train.drop(["PassengerId", "Name", "Ticket", "Cabin", "Embarked"], axis=1)
df_train = df_train.dropna(axis=0)

X_train = df_train.drop("Survived", axis=1)
y_train = df_train["Survived"]

X_test = pd.read_csv(r"./test.csv")
y_test = pd.read_csv(r"./gender_submission.csv")
df_test = pd.concat([X_test, y_test["Survived"]], axis=1)

df_test = df_test.drop(["Name", "Ticket", "Cabin", "Embarked"], axis=1)
df_test = df_test.fillna(df_test.median())
X_test_passengerId = df_test["PassengerId"]
X_test = df_test.drop(["PassengerId", "Survived"], axis=1)
y_test = df_test["Survived"]

passengerId = pd.DataFrame(X_test_passengerId)

X_train_num = X_train[["Pclass", "Age", "SibSp", "Parch", "Fare"]]
X_test_num = X_test[["Pclass","Age", "SibSp", "Parch", "Fare"]]

X_train_cat = X_train[["Sex"]]
X_test_cat = X_test[["Sex"]]

scaler = StandardScaler()
X_train_num = scaler.fit_transform(X_train_num)
X_test_num = scaler.transform(X_test_num)

encoder = LabelEncoder()
X_train_cat = encoder.fit_transform(X_train_cat)
X_test_cat = encoder.transform(X_test_cat)

X_train = np.c_[X_train_num, X_train_cat]
X_test = np.c_[X_test_num, X_test_cat]

net = models.Sequential([layers.Dense(200, activation="relu"),
                         layers.BatchNormalization(),
#                          layers.Dropout(0.5),
                         layers.Dense(150, activation="relu"),
                         layers.BatchNormalization(),
#                          layers.Dropout(0.5),
                         layers.Dense(100, activation="relu"),
                         layers.BatchNormalization(),
#                          layers.Dropout(0.5),
                         layers.Dense(20, activation="relu"),
                         layers.BatchNormalization(),
#                          layers.Dropout(0.5),
                         layers.Dense(1, activation="sigmoid")])

net.compile(optimizer="adam",
            loss="binary_crossentropy",
            metrics=["accuracy"])

H = net.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=20)

pd.DataFrame(H.history).plot(figsize=(8,6))
plt.gca()
plt.show()

evaluate = net.evaluate(X_test, y_test)

y_pred = net.predict(X_test)

y_pred = y_pred.reshape(418)
y_pred.shape

submission = pd.DataFrame({
        "PassengerId": passengerId["PassengerId"],
        "Survived": y_pred
    })
submission['Survived'][submission['Survived'] >= 0.5] = int(1)
submission['Survived'][submission['Survived'] < 0.5] = int(0)
submission = submission.astype(int)
submission.to_csv('./NNsubmission.csv', index=False)